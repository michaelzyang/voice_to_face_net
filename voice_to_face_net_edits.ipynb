{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:06:28.858363Z",
     "start_time": "2019-11-17T20:06:27.468039Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:13:38.902595Z",
     "start_time": "2019-11-21T18:13:38.894932Z"
    }
   },
   "outputs": [],
   "source": [
    "class VoiceMFCC(Dataset):\n",
    "    \"\"\"Voice MFCC spectra dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_files, standardize=False):\n",
    "        \"\"\"\n",
    "        Preconditions: csv files must contain matrices of the same dimension\n",
    "        Args:\n",
    "            csv_files (string or list): list of filenames/pathnames of csv files \n",
    "                                        with MFCC spectrogram matrices\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                                            on a sample.\n",
    "        \"\"\"\n",
    "        # ensure csv_files is a list\n",
    "        if type(csv_files) == str:\n",
    "            csv_files = [csv_files]\n",
    "        \n",
    "        # load csv files with the MFCC spectra into a 3D tensor\n",
    "        matrices = []\n",
    "        for f in csv_files:\n",
    "            matrix = np.loadtxt(f, delimiter=',', dtype=np.float32)\n",
    "            if standardize:\n",
    "                matrix = (matrix - np.mean(matrix)) / np.std(matrix)\n",
    "            matrices.append(matrix)\n",
    "        self.X = torch.Tensor(matrices)\n",
    "        N, D, M = self.X.shape\n",
    "        self.X = self.X.view(N, 1, D, M) # THIS LINE DIDNT SEEM TO FIX OUR PROBLEM...\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx]\n",
    "\n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:16:23.976995Z",
     "start_time": "2019-11-21T18:14:15.792467Z"
    }
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "csv_files = glob(\"train_mfcc/*.csv\")\n",
    "dataset = VoiceMFCC(csv_files, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:14:13.299683Z",
     "start_time": "2019-11-21T18:14:13.296954Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_3D = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:16:23.990496Z",
     "start_time": "2019-11-21T18:16:23.981863Z"
    }
   },
   "outputs": [],
   "source": [
    "# split dataset\n",
    "TRAIN_SIZE = 9099\n",
    "VALID_SIZE = 2000\n",
    "TEST_SIZE = 2000\n",
    "# TRAIN_SIZE = 100\n",
    "# VALID_SIZE = 10999\n",
    "# TEST_SIZE = 2000\n",
    "train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(dataset, \n",
    "                                                                                [TRAIN_SIZE, \n",
    "                                                                                 VALID_SIZE, \n",
    "                                                                                 TEST_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:16:23.998261Z",
     "start_time": "2019-11-21T18:16:23.994329Z"
    }
   },
   "outputs": [],
   "source": [
    "# pipe data through a dataloader for batching\n",
    "BATCH_SIZE = 20\n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T21:05:47.914373Z",
     "start_time": "2019-11-17T21:05:47.904252Z"
    }
   },
   "outputs": [],
   "source": [
    "# class autoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(autoencoder, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 8, 3, stride=3, padding=1), \n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, stride=2), \n",
    "#             nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, stride=2) ,\n",
    "#             nn.Conv2d(16, 64, 3, stride=2, padding=1),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, stride=2),\n",
    "#             nn.Conv2d(64, 128, 3, stride=2, padding=1) \n",
    "#             #nn.ReLU(True)\n",
    "#             #nn.MaxPool2d(2, stride=2)\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(128, 64, 3, stride=2), \n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64, 16, 3, stride=2, padding=1), \n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(8, 1, 3, stride=3, padding=1),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for i in self.decoder:\n",
    "#             i(x)\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:54:09.076784Z",
     "start_time": "2019-11-21T18:54:09.064301Z"
    }
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1), \n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2, stride=2), \n",
    "                nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "                nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2, stride=2),\n",
    "                nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.ModuleList(\n",
    "            [\n",
    "                nn.ConvTranspose2d(1, 64, kernel_size=3, stride=1, padding=1), \n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(64, 16, kernel_size=3, stride=2, padding=(1,0),output_padding = (1,0)), \n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=(1,1),output_padding = (1,1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=(1,0), output_padding = (1,0)),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"shape start: {}\".format(x.shape))\n",
    "        \n",
    "        #print(\"start encoder\")\n",
    "        for layer in self.encoder:\n",
    "            x = layer.forward(x)\n",
    "            #print(x.shape)\n",
    "        \n",
    "        # flatten bottleneck into vectors\n",
    "        N, _, H, W = x.shape\n",
    "        w = x.view(N, H * W)\n",
    "        \n",
    "        #print(\"start decoder\")     \n",
    "        for layer in self.decoder:\n",
    "            x = layer.forward(x)\n",
    "            #print(x.shape)\n",
    "        \n",
    "        return x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:54:09.486102Z",
     "start_time": "2019-11-21T18:54:09.478532Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = autoencoder().cuda()\n",
    "NUM_EPOCHS = 250\n",
    "LEARNING_RATE = 1e-3\n",
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:54:10.772893Z",
     "start_time": "2019-11-21T18:54:10.711855Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [10/250], loss:0.6155\n",
      "epoch [20/250], loss:0.6052\n",
      "epoch [30/250], loss:0.6005\n",
      "epoch [40/250], loss:0.6131\n",
      "epoch [50/250], loss:0.6036\n",
      "epoch [60/250], loss:0.6057\n",
      "epoch [70/250], loss:0.5980\n",
      "epoch [80/250], loss:0.6146\n",
      "epoch [90/250], loss:0.6132\n",
      "epoch [100/250], loss:0.5939\n",
      "epoch [110/250], loss:0.6124\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in dataloader:\n",
    "        # ===================forward=====================\n",
    "        output, w = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    if((epoch+1)%10 == 0):\n",
    "        print('epoch [{}/{}], loss:{:.4f}'\n",
    "              .format(epoch+1, NUM_EPOCHS, loss.data.item())) # EDIT: changed [0] to .item()\n",
    "\n",
    "torch.save(model.state_dict(), './model_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that NN outputs the same size file as input\n",
    "# FID for similarity between faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:54:09.705752Z",
     "start_time": "2019-11-21T18:54:09.701928Z"
    }
   },
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    temp = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T18:54:10.059305Z",
     "start_time": "2019-11-21T18:54:10.055300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 40, 173])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
